{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/xqwu1108-create/MSE1003H_XueqiuWu_1011808741/blob/main/A1.ipynb",
      "authorship_tag": "ABX9TyOMkRoIc7+qN1J2zoRs5hA1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1.Introduction**"
      ],
      "metadata": {
        "id": "_Blfwobdbvdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project uses a dataset sourced from the Materials Project, consisting of 3000 inorganic material samples. To ensure data quality and relevance, materials were specifically selected within a bandgap range of 0.1 to 8.0 eV. The dataset includes various physical and chemical descriptors, such as formation energy, density, and atomic properties. The research objective is to develop and evaluate a machine learning pipeline to accurately predict the bandgap of materials, which incorporated dimensinality reduction and Random Forest regression."
      ],
      "metadata": {
        "id": "2vjW9xhd0BGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.Analysis**"
      ],
      "metadata": {
        "id": "W6er0QKObumu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.1 Dataset Research and Loading**"
      ],
      "metadata": {
        "id": "IuMin_ytckCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The research question is to predict the bandgap of materials using a regression model based on chemical descriptors。"
      ],
      "metadata": {
        "id": "f12SnO712k96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pymatgen\n",
        "! pip install mp_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fswss08HtHMK",
        "outputId": "1f59eb9f-204d-4ac9-a321-1da8df87e3d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymatgen\n",
            "  Downloading pymatgen-2025.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting bibtexparser>=1.4.0 (from pymatgen)\n",
            "  Downloading bibtexparser-1.4.3.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (3.10.0)\n",
            "Collecting monty>=2025.1.9 (from pymatgen)\n",
            "  Downloading monty-2025.3.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (3.6.1)\n",
            "Requirement already satisfied: numpy<3,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (2.0.2)\n",
            "Requirement already satisfied: orjson<4,>=3.10 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (3.11.5)\n",
            "Collecting palettable>=3.3.3 (from pymatgen)\n",
            "  Downloading palettable-3.3.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pandas>=2 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (2.2.2)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (5.24.1)\n",
            "Requirement already satisfied: requests>=2.30 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (2.32.4)\n",
            "Collecting ruamel.yaml>=0.17.0 (from pymatgen)\n",
            "  Downloading ruamel_yaml-0.19.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (1.16.3)\n",
            "Collecting spglib>=2.5 (from pymatgen)\n",
            "  Downloading spglib-2.7.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (1.14.0)\n",
            "Requirement already satisfied: tabulate>=0.9 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.60 in /usr/local/lib/python3.12/dist-packages (from pymatgen) (4.67.1)\n",
            "Collecting uncertainties>=3.1.4 (from pymatgen)\n",
            "  Downloading uncertainties-3.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from bibtexparser>=1.4.0->pymatgen) (3.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen) (11.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2->pymatgen) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2->pymatgen) (2025.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=5.0.0->pymatgen) (9.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30->pymatgen) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30->pymatgen) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30->pymatgen) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30->pymatgen) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from spglib>=2.5->pymatgen) (4.15.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.3->pymatgen) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8->pymatgen) (1.17.0)\n",
            "Downloading pymatgen-2025.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monty-2025.3.3-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading palettable-3.3.3-py2.py3-none-any.whl (332 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.3/332.3 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel_yaml-0.19.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spglib-2.7.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.5/962.5 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uncertainties-3.2.3-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: bibtexparser\n",
            "  Building wheel for bibtexparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bibtexparser: filename=bibtexparser-1.4.3-py3-none-any.whl size=43549 sha256=7b79ce7d85a0aa5c5ad161b3c7b85cad7899d6a479b1b875418c23d8c135977a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/7d/e9/1ff2509f13767a55df1279744adfb757f4ab94b2cbe761f56a\n",
            "Successfully built bibtexparser\n",
            "Installing collected packages: uncertainties, spglib, ruamel.yaml, palettable, bibtexparser, monty, pymatgen\n",
            "Successfully installed bibtexparser-1.4.3 monty-2025.3.3 palettable-3.3.3 pymatgen-2025.10.7 ruamel.yaml-0.19.1 spglib-2.7.0 uncertainties-3.2.3\n",
            "Collecting mp_api\n",
            "  Downloading mp_api-0.45.15-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from mp_api) (1.1.2)\n",
            "Requirement already satisfied: pymatgen!=2024.2.20,>=2022.3.7 in /usr/local/lib/python3.12/dist-packages (from mp_api) (2025.10.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.12/dist-packages (from mp_api) (4.15.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from mp_api) (2.32.4)\n",
            "Requirement already satisfied: monty>=2024.12.10 in /usr/local/lib/python3.12/dist-packages (from mp_api) (2025.3.3)\n",
            "Collecting emmet-core>=0.86.2 (from mp_api)\n",
            "  Downloading emmet_core-0.86.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.12/dist-packages (from mp_api) (7.5.0)\n",
            "Collecting boto3 (from mp_api)\n",
            "  Downloading boto3-1.42.34-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: orjson<4,>=3.10 in /usr/local/lib/python3.12/dist-packages (from mp_api) (3.11.5)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from emmet-core>=0.86.2->mp_api) (2.12.3)\n",
            "Requirement already satisfied: pydantic-settings>=2.0 in /usr/local/lib/python3.12/dist-packages (from emmet-core>=0.86.2->mp_api) (2.12.0)\n",
            "Collecting pymatgen-io-validation>=0.1.1 (from emmet-core>=0.86.2->mp_api)\n",
            "  Downloading pymatgen_io_validation-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pybtex~=0.24 (from emmet-core>=0.86.2->mp_api)\n",
            "  Downloading pybtex-0.25.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting blake3 (from emmet-core>=0.86.2->mp_api)\n",
            "  Downloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: ruamel.yaml in /usr/local/lib/python3.12/dist-packages (from monty>=2024.12.10->mp_api) (0.19.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from monty>=2024.12.10->mp_api) (2.0.2)\n",
            "Requirement already satisfied: bibtexparser>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (1.4.3)\n",
            "Requirement already satisfied: joblib>=1 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (3.10.0)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (3.6.1)\n",
            "Requirement already satisfied: palettable>=3.3.3 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (3.3.3)\n",
            "Requirement already satisfied: pandas>=2 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (2.2.2)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (5.24.1)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (1.16.3)\n",
            "Requirement already satisfied: spglib>=2.5 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (2.7.0)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (1.14.0)\n",
            "Requirement already satisfied: tabulate>=0.9 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.60 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (4.67.1)\n",
            "Requirement already satisfied: uncertainties>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from pymatgen!=2024.2.20,>=2022.3.7->mp_api) (3.2.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->mp_api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->mp_api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->mp_api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->mp_api) (2026.1.4)\n",
            "Collecting botocore<1.43.0,>=1.42.34 (from boto3->mp_api)\n",
            "  Downloading botocore-1.42.34-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->mp_api)\n",
            "  Downloading jmespath-1.1.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3->mp_api)\n",
            "  Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open->mp_api) (2.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from bibtexparser>=1.4.0->pymatgen!=2024.2.20,>=2022.3.7->mp_api) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.34->boto3->mp_api) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen!=2024.2.20,>=2022.3.7->mp_api) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen!=2024.2.20,>=2022.3.7->mp_api) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen!=2024.2.20,>=2022.3.7->mp_api) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen!=2024.2.20,>=2022.3.7->mp_api) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen!=2024.2.20,>=2022.3.7->mp_api) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen!=2024.2.20,>=2022.3.7->mp_api) (11.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2->pymatgen!=2024.2.20,>=2022.3.7->mp_api) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2->pymatgen!=2024.2.20,>=2022.3.7->mp_api) (2025.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=5.0.0->pymatgen!=2024.2.20,>=2022.3.7->mp_api) (9.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.01 in /usr/local/lib/python3.12/dist-packages (from pybtex~=0.24->emmet-core>=0.86.2->mp_api) (6.0.3)\n",
            "Collecting latexcodec>=1.0.4 (from pybtex~=0.24->emmet-core>=0.86.2->mp_api)\n",
            "  Downloading latexcodec-3.0.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->emmet-core>=0.86.2->mp_api) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->emmet-core>=0.86.2->mp_api) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->emmet-core>=0.86.2->mp_api) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.0->emmet-core>=0.86.2->mp_api) (1.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.3->pymatgen!=2024.2.20,>=2022.3.7->mp_api) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.34->boto3->mp_api) (1.17.0)\n",
            "Downloading mp_api-0.45.15-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emmet_core-0.86.2-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.8/306.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.42.34-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.42.34-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading pybtex-0.25.1-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymatgen_io_validation-0.1.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading latexcodec-3.0.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: latexcodec, jmespath, blake3, pybtex, botocore, s3transfer, pymatgen-io-validation, boto3, emmet-core, mp_api\n",
            "Successfully installed blake3-1.0.8 boto3-1.42.34 botocore-1.42.34 emmet-core-0.86.2 jmespath-1.1.0 latexcodec-3.0.1 mp_api-0.45.15 pybtex-0.25.1 pymatgen-io-validation-0.1.2 s3transfer-0.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install matminer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jH59zHbouGz4",
        "outputId": "effca075-297d-48df-a6bf-41a6f1e5e7d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matminer\n",
            "  Downloading matminer-0.10.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matminer) (2.0.2)\n",
            "Requirement already satisfied: requests~=2.31 in /usr/local/lib/python3.12/dist-packages (from matminer) (2.32.4)\n",
            "Requirement already satisfied: pandas<3,>=1.5 in /usr/local/lib/python3.12/dist-packages (from matminer) (2.2.2)\n",
            "Requirement already satisfied: tqdm~=4.66 in /usr/local/lib/python3.12/dist-packages (from matminer) (4.67.1)\n",
            "Collecting pymongo~=4.5 (from matminer)\n",
            "  Downloading pymongo-4.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: scikit-learn~=1.3 in /usr/local/lib/python3.12/dist-packages (from matminer) (1.6.1)\n",
            "Requirement already satisfied: sympy~=1.11 in /usr/local/lib/python3.12/dist-packages (from matminer) (1.14.0)\n",
            "Requirement already satisfied: monty>=2023 in /usr/local/lib/python3.12/dist-packages (from matminer) (2025.3.3)\n",
            "Requirement already satisfied: pymatgen>=2023 in /usr/local/lib/python3.12/dist-packages (from matminer) (2025.10.7)\n",
            "Collecting scipy>=1.17.0 (from matminer)\n",
            "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ruamel.yaml in /usr/local/lib/python3.12/dist-packages (from monty>=2023->matminer) (0.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.5->matminer) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.5->matminer) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.5->matminer) (2025.3)\n",
            "Requirement already satisfied: bibtexparser>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from pymatgen>=2023->matminer) (1.4.3)\n",
            "Requirement already satisfied: joblib>=1 in /usr/local/lib/python3.12/dist-packages (from pymatgen>=2023->matminer) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from pymatgen>=2023->matminer) (3.10.0)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.12/dist-packages (from pymatgen>=2023->matminer) (3.6.1)\n",
            "Requirement already satisfied: orjson<4,>=3.10 in /usr/local/lib/python3.12/dist-packages (from pymatgen>=2023->matminer) (3.11.5)\n",
            "Requirement already satisfied: palettable>=3.3.3 in /usr/local/lib/python3.12/dist-packages (from pymatgen>=2023->matminer) (3.3.3)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from pymatgen>=2023->matminer) (5.24.1)\n",
            "Requirement already satisfied: spglib>=2.5 in /usr/local/lib/python3.12/dist-packages (from pymatgen>=2023->matminer) (2.7.0)\n",
            "Requirement already satisfied: tabulate>=0.9 in /usr/local/lib/python3.12/dist-packages (from pymatgen>=2023->matminer) (0.9.0)\n",
            "Requirement already satisfied: uncertainties>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from pymatgen>=2023->matminer) (3.2.3)\n",
            "Collecting dnspython<3.0.0,>=2.6.1 (from pymongo~=4.5->matminer)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.31->matminer) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.31->matminer) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.31->matminer) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.31->matminer) (2026.1.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn~=1.3->matminer) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy~=1.11->matminer) (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from bibtexparser>=1.4.0->pymatgen>=2023->matminer) (3.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen>=2023->matminer) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen>=2023->matminer) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen>=2023->matminer) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen>=2023->matminer) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen>=2023->matminer) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->pymatgen>=2023->matminer) (11.3.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=5.0.0->pymatgen>=2023->matminer) (9.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.5->matminer) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from spglib>=2.5->pymatgen>=2023->matminer) (4.15.0)\n",
            "Downloading matminer-0.10.0-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, dnspython, pymongo, matminer\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "Successfully installed dnspython-2.8.0 matminer-0.10.0 pymongo-4.16.0 scipy-1.17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "scipy"
                ]
              },
              "id": "54390f6c6e2847fb8568c4a8e9f39336"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BtvHKJXmunPC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "56a9ed18-3927-4bc4-fec0-38a416b4e88b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-339935415.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmp_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPRester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpymatgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomposition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mp_api/client/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPackageNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPRestError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmprester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPRester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mp_api/client/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseRester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMPRestError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMPRestWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAPIClientSettings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mp_api/client/core/client.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0memmet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjsanitize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPAdapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/emmet/core/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRootModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlenient_issubclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpymatgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melasticity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpymatgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMoleculeGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpymatgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenBabelNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetal_edge_extender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymatgen/analysis/elasticity/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from .elastic import (\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mComplianceTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mElasticTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymatgen/analysis/elasticity/elastic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/polys/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m         GroebnerBasis, poly)\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m from .polyfuncs import (symmetrize, horner, interpolate,\n\u001b[0m\u001b[1;32m     80\u001b[0m         rational_interpolate, viete)\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/polys/polyfuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyoptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallowed_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpoly_from_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from sympy.polys.specialpolys import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     symmetric_poly, interpolating_poly)\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/polys/specialpolys.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;31m# A few useful polynomials from Wang's paper ('78).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_f_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/polys/rings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m from sympy.polys.polyutils import (expr_from_dict, _dict_reorder,\n\u001b[1;32m     30\u001b[0m                                    _parallel_dict_from_expr)\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultPrinting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpublic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/printing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpython\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_ccode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_fcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/printing/pycode.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCodePrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m _kw = {\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/printing/codeprinter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault_sort_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrPrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRECEDENCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/functions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m from sympy.functions.elementary.exponential import (exp_polar, exp, log,\n\u001b[1;32m     22\u001b[0m         LambertW)\n\u001b[0;32m---> 23\u001b[0;31m from sympy.functions.elementary.hyperbolic import (sinh, cosh, tanh, coth,\n\u001b[0m\u001b[1;32m     24\u001b[0m         sech, csch, asinh, acosh, atanh, acoth, asech, acsch)\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfloor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceiling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from mp_api.client import MPRester\n",
        "from pymatgen.core import Composition\n",
        "from matminer.featurizers import composition as cf\n",
        "from matminer.featurizers.conversions import StrToComposition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the secret named 'MP_API_KEY'\n",
        "api_key = userdata.get('MP_API_KEY')\n",
        "\n",
        "# Check for existence and valid length (32 chars for the new API)\n",
        "if not api_key:\n",
        "    print(\"Error: Could not find 'MP_API_KEY' in Secrets.\")\n",
        "elif len(api_key) != 32:\n",
        "    print(f\"Error: Key length is {len(api_key)}. The new API requires a 32-character key.\")\n",
        "else:\n",
        "    print(\"Success: MP_API key retrieved from Secrets.\")\n",
        "# Reset the list INSIDE this cell\n",
        "    material_data = []\n",
        "\n",
        "    try:\n",
        "        # Initialize the Materials Project requester with the environment key\n",
        "        with MPRester(api_key) as mpr:\n",
        "            # Search for materials based on specific physical constraints\n",
        "            # Criteria: Bandgap 0.1-8.0 eV, containing 1 to 4 unique elements\n",
        "            docs = mpr.materials.summary.search(\n",
        "                band_gap=(0.1, 8.0),\n",
        "                num_elements=(1, 4),\n",
        "                fields=[\n",
        "                    \"material_id\", \"formula_pretty\", \"composition\",\n",
        "                    \"band_gap\", \"formation_energy_per_atom\", \"density\",\n",
        "                    \"volume\", \"nsites\", \"nelements\"\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            print(f\"Connection successful. Retrieved {len(docs)} matching entries.\")\n",
        "\n",
        "            # Processing the first 3000 entries for demonstration purposes\n",
        "            for doc in docs[:3000]:\n",
        "                material_data.append({\n",
        "                    'material_id': doc.material_id,\n",
        "                    'formula': doc.formula_pretty,\n",
        "                    'composition': str(doc.composition),\n",
        "                    'bandgap_eV': doc.band_gap,\n",
        "                    'formation_energy': doc.formation_energy_per_atom,\n",
        "                    'density_gcc': doc.density,\n",
        "                    'volume_A3': doc.volume,\n",
        "                    'n_atoms': doc.nsites,\n",
        "                    'n_elements': doc.nelements\n",
        "                })\n",
        "\n",
        "        # Create structured DataFrame\n",
        "        df = pd.DataFrame(material_data)\n",
        "\n",
        "        print(\"\\nData Loading Statistics:\")\n",
        "        print(f\"Total entries processed: {len(df)}\")\n",
        "        if not df.empty:\n",
        "            # Display stats using LaTeX notation in output strings for clarity\n",
        "            print(f\"Bandgap Range: {df['bandgap_eV'].min():.2f} eV to {df['bandgap_eV'].max():.2f} eV\")\n",
        "            print(f\"Dataframe Shape: {df.shape}\")\n",
        "\n",
        "            print(\"\\nHead of the processed dataset:\")\n",
        "            print(df.head())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "XbXgD7BYZs_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Dataset Target Distribution\n",
        "plt.figure(figsize=(9, 5))\n",
        "sns.histplot(y, kde=True, color='royalblue', bins=30)\n",
        "\n",
        "# Add statistical reference lines\n",
        "plt.axvline(y.mean(), color='red', linestyle='--', label=f'Mean: {y.mean():.2f} eV')\n",
        "plt.axvline(y.median(), color='green', linestyle='-', label=f'Median: {y.median():.2f} eV')\n",
        "\n",
        "plt.title('Statistical Distribution of Bandgap Values', fontsize=14)\n",
        "plt.xlabel('Bandgap (eV)', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XEi9d9hhA5ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the distribution, a larger concentration of materials exists at lower bandgap values. The mean bandgap is 2.36 eV, while the median is 2.06 eV.The peak frequency occurs at very low bandgap values, suggesting the presence of a substantial number of narrow-gap materials in the sample."
      ],
      "metadata": {
        "id": "1WjxSgB2cMwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.2 Data Preprocessing and Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "hg7iBzgNw_kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select 600 rows from the dataframe for the test partition\n",
        "test_sample = df.sample(n=min(600, len(df)), random_state=1003)\n",
        "\n",
        "print(f\"Original dataframe size: {len(df)} rows\")\n",
        "print(f\"Test partition size: {len(test_sample)} rows\")\n",
        "print(f\"Percentage of data selected: {len(test_sample)/len(df)*100:.1f}%\")\n",
        "\n",
        "print(f\"\\nTest partition bandgap range: {test_sample['bandgap_eV'].min():.2f} - {test_sample['bandgap_eV'].max():.2f} eV\")\n",
        "print(f\"Test partition shape: {test_sample.shape}\")\n",
        "\n",
        "# Remove test_sample from main dataframe\n",
        "df_remaining = df.drop(test_sample.index)\n",
        "\n",
        "print(f\"\\nRemaining dataframe size after removing test partition: {len(df_remaining)} rows\")\n",
        "print(f\"Rows removed: {len(df) - len(df_remaining)} rows\")\n",
        "print(f\"Remaining dataframe shape: {df_remaining.shape}\")\n",
        "\n",
        "# Ensure there's no intersection between sets to maintain evaluation integrity\n",
        "assert len(set(df_remaining.index).intersection(set(test_sample.index))) == 0, \"Overlap found!\"\n",
        "print(\"✔ Successfully removed test partition - no overlap detected\")\n",
        "\n",
        "# Reset index for clean downstream processing\n",
        "train_df = df_remaining.reset_index(drop=True)\n",
        "test_df = test_sample.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "8Y2FO-5Q7_4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data preprocessing and EDA\n",
        "print(\"Train Dataset Information:\")\n",
        "# Check data types, non-null counts, and memory usage\n",
        "print(train_df.info())\n",
        "print(\"\\nSummary Statistics:\")\n",
        "# Display stats (mean, std, quartiles, etc.)\n",
        "print(train_df.describe())\n",
        "print(\"\\nMissing values per column:\")\n",
        "# Count null values in each column\n",
        "print(train_df.isnull().sum())"
      ],
      "metadata": {
        "id": "X1qhlVHYwoQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Train Data Distributions\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "# Bandgap distribution (target variable)\n",
        "axes[0,0].hist(train_df['bandgap_eV'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[0,0].set_title('Bandgap Distribution')\n",
        "axes[0,0].set_xlabel('Bandgap (eV)')\n",
        "axes[0,0].set_ylabel('Frequency')\n",
        "\n",
        "# Formation energy distribution\n",
        "axes[0,1].hist(train_df['formation_energy'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "axes[0,1].set_title('Formation Energy Distribution')\n",
        "axes[0,1].set_xlabel('Formation Energy (eV)')\n",
        "axes[0,1].set_ylabel('Frequency')\n",
        "\n",
        "# Density distribution\n",
        "axes[0,2].hist(train_df['density_gcc'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "axes[0,2].set_title('Density Distribution')\n",
        "axes[0,2].set_xlabel('Density (g/cm3)')\n",
        "axes[0,2].set_ylabel('Frequency')\n",
        "\n",
        "# Volume distribution\n",
        "axes[1,0].hist(train_df['volume_A3'], bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
        "axes[1,0].set_title('Volume Distribution')\n",
        "axes[1,0].set_xlabel('Volume (Å^3)')\n",
        "axes[1,0].set_ylabel('Frequency')\n",
        "\n",
        "# Number of atoms distribution\n",
        "axes[1,1].hist(train_df['n_atoms'], bins=20, alpha=0.7, color='purple', edgecolor='black')\n",
        "axes[1,1].set_title('Number of Atoms Distribution')\n",
        "axes[1,1].set_xlabel('Number of Atoms')\n",
        "axes[1,1].set_ylabel('Frequency')\n",
        "\n",
        "# Number of elements distribution\n",
        "axes[1,2].hist(train_df['n_elements'], bins=10, alpha=0.7, color='gold', edgecolor='black')\n",
        "axes[1,2].set_title('Number of Elements Distribution')\n",
        "axes[1,2].set_xlabel('Number of Elements')\n",
        "axes[1,2].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout() # Adjust layout to prevent overlap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZrvJ8HMw0DIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is primarily composed of chemically diverse ternary and quaternary materials that are thermodynamically stable, with negative formation energies. Most entries feature relatively simple crystal structures characterized by small unit cell volumes."
      ],
      "metadata": {
        "id": "RbOjfJOtdNGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Automatically select numerical columns\n",
        "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Remove the target variable to analyze feature-only correlation\n",
        "numeric_cols_for_corr = numeric_cols.drop('bandgap_eV')\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = train_df[numeric_cols_for_corr].corr()\n",
        "\n",
        "# Visualize with a heatmap\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, square=True, linewidths=0.5)\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W6ycy6QS0DYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation matrix highlights a strong positive relationship (0.69) between unit cell volume and the number of atoms, while other physical descriptors show minimal coupling."
      ],
      "metadata": {
        "id": "cDiBtrcefncF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.3 Feature Engineering with Materials Informatics**"
      ],
      "metadata": {
        "id": "OAJ2exOm6Adj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of train_df to avoid modifying the original training data\n",
        "feature_df = train_df.copy()\n",
        "\n",
        "# Convert strings to Composition objects\n",
        "stc = StrToComposition(target_col_id='composition_obj')\n",
        "# featurize_dataframe add 'composition_obj'\n",
        "feature_df = stc.featurize_dataframe(feature_df, \"composition\")\n",
        "\n",
        "print(f\"Dataset shape after composition conversion: {feature_df.shape}\")\n",
        "\n",
        "# Selected key descriptors to balance model accuracy and computational complexity\n",
        "featurizers = [\n",
        "    cf.ElementProperty.from_preset(\"magpie\"), # Elemental properties\n",
        "    cf.Stoichiometry(),                      #  Stoichiometric features\n",
        "    cf.ElementFraction(),                    # Element fraction features\n",
        "    cf.TMetalFraction(),                     # Transition metal fraction\n",
        "]\n",
        "\n",
        "# Apply featurizers one by one\n",
        "print(\"Applying featurizers...\")\n",
        "\n",
        "for i, featurizer in enumerate(featurizers):\n",
        "    try:\n",
        "        print(f\"Applying featurizer {i+1}/{len(featurizers)}: {featurizer.__class__.__name__}\")\n",
        "\n",
        "\n",
        "        # Add features to dataframe, use ignore_errors=True to skip problematic entries\n",
        "        feature_df = featurizer.featurize_dataframe(feature_df, col_id=\"composition_obj\", ignore_errors=True)\n",
        "\n",
        "        print(f\"Shape after {featurizer.__class__.__name__}: {feature_df.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error with featurizer {featurizer.__class__.__name__}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"Final dataset shape after featurization: {feature_df.shape}\")\n",
        "\n",
        "\n",
        "# Remove non-numeric columns like formula strings and composition objects\n",
        "non_feature_cols = ['composition', 'pretty_formula', 'composition_obj', 'material_id', 'formula']\n",
        "# Select columns with numerical data types\n",
        "feature_cols = [col for col in feature_df.columns if col not in non_feature_cols]\n",
        "numeric_features = feature_df[feature_cols].select_dtypes(include=[np.number])\n",
        "\n",
        "print(f\"Number of numeric features: {numeric_features.shape[1]}\")\n",
        "\n",
        "# Clean the dataset\n",
        "# For missing values: fill them with median\n",
        "numeric_features = numeric_features.replace([np.inf, -np.inf], np.nan)\n",
        "numeric_features = numeric_features.fillna(numeric_features.median())\n",
        "\n",
        "# Target y is the bandgap; feature matrix X includes all other numerical descriptors\n",
        "y = numeric_features['bandgap_eV'].copy()\n",
        "X = numeric_features.drop(['bandgap_eV'], axis=1)\n",
        "\n",
        "print(f\"Target variable shape: {y.shape}\")\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "# Show names of the first 10 descriptors\n",
        "print(f\"Sample features: {list(X.columns[:10])}\")"
      ],
      "metadata": {
        "id": "GYXxIExR6AIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the test dataframe to ensure the original raw data remains untouched\n",
        "test_feature_df = test_df.copy()\n",
        "\n",
        "\n",
        "# Use the StrToComposition (stc) featurizer to convert chemical formula strings\n",
        "test_feature_df = stc.featurize_dataframe(test_feature_df, \"composition\")\n",
        "\n",
        "print(f\"Test dataset shape after composition conversion: {test_feature_df.shape}\")\n",
        "\n",
        "# Iteratively apply the same list of featurizers used for the training set.\n",
        "print(\"Applying featurizers to test data...\")\n",
        "\n",
        "for i, featurizer in enumerate(featurizers):\n",
        "    try:\n",
        "        # Display progress and the name of the current featurizer class\n",
        "        print(f\"Applying featurizer {i+1}/{len(featurizers)}: {featurizer.__class__.__name__}\")\n",
        "\n",
        "        # Extract features based on the \"composition_obj\" column.\n",
        "        test_feature_df = featurizer.featurize_dataframe(test_feature_df, col_id=\"composition_obj\", ignore_errors=True)\n",
        "\n",
        "        print(f\"Shape after {featurizer.__class__.__name__}: {test_feature_df.shape}\")\n",
        "    except Exception as e:\n",
        "        # Catch and report any catastrophic errors specific to a featurizer\n",
        "        print(f\"Error with featurizer {featurizer.__class__.__name__}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"Final test dataset shape after featurization: {test_feature_df.shape}\")\n",
        "\n",
        "# Extract only the columns that were defined during the training phase.\n",
        "test_numeric_features = test_feature_df[feature_cols].select_dtypes(include=[np.number])\n",
        "\n",
        "# Data Cleaning\n",
        "test_numeric_features = test_numeric_features.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Fill missing values (NaN) using the median of the current column.\n",
        "test_numeric_features = test_numeric_features.fillna(test_numeric_features.median())\n",
        "\n",
        "# Extract the ground truth target variable ('bandgap_ev') for final evaluation.\n",
        "y_test_true = test_numeric_features['bandgap_eV'].copy()\n",
        "X_test_raw = test_numeric_features.drop(['bandgap_eV'], axis=1)\n",
        "\n",
        "# Drop the target column from the feature matrix to prevent data leakage.\n",
        "X_test_features = test_numeric_features.drop(['bandgap_eV'], axis=1)\n",
        "\n",
        "print(f\"Test target variable shape: {y_test_true.shape}\")\n",
        "print(f\"Test feature matrix shape: {X_test_features.shape}\")\n",
        "print(\"Test data featurization complete\")"
      ],
      "metadata": {
        "id": "wnCr3vVq76dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Correlation Matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = numeric_features.corr()\n",
        "\n",
        "# Draw heatmap to check for multicollinearity between features\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Matrix for Training Dataset')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X0tVt9ydwUdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the top 20 most correlated features\n",
        "target_corr = numeric_features.corr()['bandgap_eV'].abs().sort_values(ascending=False)\n",
        "\n",
        "# Select the top 20 features\n",
        "top_20_features = target_corr.head(21).index\n",
        "\n",
        "# Create the filtered correlation matrix\n",
        "filtered_corr_matrix = numeric_features[top_20_features].corr()\n",
        "\n",
        "# Plot the Heatmap\n",
        "plt.figure(figsize=(14, 12))\n",
        "\n",
        "\n",
        "sns.heatmap(\n",
        "    filtered_corr_matrix,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap='coolwarm',\n",
        "    center=0,\n",
        "    square=True,\n",
        "    linewidths=0.5,\n",
        "    cbar_kws={\"shrink\": .8}\n",
        ")\n",
        "\n",
        "plt.title('Top 20 Features Correlated with Bandgap in Train Data', fontsize=16)\n",
        "plt.xticks(rotation=45, ha='right') # Rotate labels for better readability\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Highest correlations with bandgap\n",
        "print(\"\\nHighest correlations with bandgap_eV:\")\n",
        "# Sort features by absolute correlation with the target\n",
        "bandgap_correlations = correlation_matrix['bandgap_eV'].abs().sort_values(ascending=False)\n",
        "print(bandgap_correlations.head(10))"
      ],
      "metadata": {
        "id": "hHaAk1enzh2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The features most strongly correlated with the bandgap are primarily centered on intrinsic atomic properties and electronic configurations. The data reveals that the periodic table position (Row, Atomic Number/Weight), atomic size (CovalentRadius), and descriptors related to valence electrons (NdValence) are the strongest predictors, with correlation coefficients typically between 0.4 and 0.5."
      ],
      "metadata": {
        "id": "0vrrqIUEtzIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.4 Dimensionality Reduction**"
      ],
      "metadata": {
        "id": "LnnaZm9y1V0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Principal Component Analysis\n",
        "n_components = min(60, X.shape[0]-1)\n",
        "pca = PCA(n_components=n_components, random_state=1003)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# t-SNE for Visualization\n",
        "if X.shape[0] > 30:\n",
        "    tsne = TSNE(n_components=2, random_state=1003, perplexity=min(30, X.shape[0]//3))\n",
        "    X_tsne = tsne.fit_transform(X_pca[:, :min(10, n_components)])\n",
        "else:\n",
        "    X_tsne = None\n",
        "\n",
        "# Visualizing Results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Bar plot for individual explained variance\n",
        "axes[0,0].bar(range(1, len(pca.explained_variance_ratio_[:10])+1), pca.explained_variance_ratio_[:10])\n",
        "axes[0,0].set_title('PCA Explained Variance Ratio')\n",
        "axes[0,0].set_xlabel('Principal Component')\n",
        "axes[0,0].set_ylabel('Variance Ratio')\n",
        "\n",
        "# Cumulative explained variance plot\n",
        "cumsum_var = np.cumsum(pca.explained_variance_ratio_)\n",
        "axes[0,1].plot(range(1, len(cumsum_var)+1), cumsum_var, 'bo-')\n",
        "axes[0,1].set_title('Cumulative Explained Variance')\n",
        "axes[0,1].grid(True)\n",
        "\n",
        "# PCA scatter plot colored by Bandgap\n",
        "scatter = axes[1,0].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.7)\n",
        "axes[1,0].set_title('PCA: First 2 Components')\n",
        "plt.colorbar(scatter, ax=axes[1,0], label='Bandgap (eV)')\n",
        "\n",
        "# plot t-SNE\n",
        "if X_tsne is not None:\n",
        "    scatter2 = axes[1,1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='viridis', alpha=0.7)\n",
        "    axes[1,1].set_title('t-SNE Visualization')\n",
        "    plt.colorbar(scatter2, ax=axes[1,1], label='Bandgap (eV)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Use PCA features for further analysis ---\n",
        "X_reduced = X_pca\n",
        "print(f\"\\nUsing PCA-reduced features with {X_reduced.shape[1]} components for modeling\")"
      ],
      "metadata": {
        "id": "XA_k18QC1WNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PCA results indicate that the first two principal components account for only about 23% of the variance, with approximately 50 components required to reach an 80% cumulative explained variance ratio. The t-SNE visualization reveals more distinct local clusters; crucially, both methods demonstrate that bandgap values cluster systematically within the feature space rather than appearing at random. It confirms that the selected descriptors effectively capture the underlying physics governing the electronic properties"
      ],
      "metadata": {
        "id": "kxFK3K_yscbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Determining Optimal num_clusters using the Elbow Method\n",
        "# test k values from 1 to 10\n",
        "inertia = []\n",
        "k_range = range(1, 11)\n",
        "\n",
        "for k in k_range:\n",
        "    # Use the same random_state for consistency across tests\n",
        "    km = KMeans(n_clusters=k, random_state=1003, n_init=10)\n",
        "    km.fit(X_reduced)\n",
        "    inertia.append(km.inertia_)\n",
        "\n",
        "# Plotting the Elbow Curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_range, inertia, 'bo-')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia (SSE)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nsYhJeG7D8jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the Elbow Method analysis, the inertia decreases sharply until k=4 and begins to plateau after k=5. Therefore, k=4 was selected as the optimal number of clusters."
      ],
      "metadata": {
        "id": "TPjdoYIyER7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Means Clustering on PCA-Reduced Data\n",
        "num_clusters = 4 # based on the elbow method\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=1003, n_init=10)\n",
        "cluster_labels = kmeans.fit_predict(X_reduced)\n",
        "\n",
        "# Plot the first two Principal Components colored by Cluster ID\n",
        "plt.figure(figsize=(10, 7))\n",
        "scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=cluster_labels, cmap='viridis', alpha=0.6, edgecolors='k')\n",
        "\n",
        "# Add a color bar to indicate Cluster ID as required by the assignment\n",
        "cbar = plt.colorbar(scatter)\n",
        "cbar.set_label('Cluster ID', fontsize=12)\n",
        "\n",
        "plt.title('Reduced Dimensionality Dataset Labeled by Cluster', fontsize=14)\n",
        "plt.xlabel('Principal Component 1 (PC1)', fontsize=12)\n",
        "plt.ylabel('Principal Component 2 (PC2)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uvk48BY4Ch90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The clustering plot demonstrates that the algorithm successfully partitioned the dataset into four distinct groups based on their principal component scores, revealing a natural organization of materials within the feature space. Cluster 3 (yellow) is tightly concentrated at low PC1 and PC2 values, whereas Cluster 1 (blue) and Cluster 2 (green) are more widely dispersed across the positive PC1 range."
      ],
      "metadata": {
        "id": "FweIuX8puTiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.5 Feature Selection**"
      ],
      "metadata": {
        "id": "qql0PsVE4P27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Optimizing k via CV\n",
        "print(\"Searching for the optimal k value...\")\n",
        "k_values = range(1, 61)\n",
        "cv_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    selector = SelectKBest(score_func=f_regression, k=k)\n",
        "    X_tmp = selector.fit_transform(X_reduced, y)\n",
        "\n",
        "    # CV for accuracy\n",
        "    model = RandomForestRegressor(n_estimators=50, random_state=1003, n_jobs=-1)\n",
        "    scores = cross_val_score(model, X_tmp, y, cv=5, scoring='r2')\n",
        "    cv_scores.append(scores.mean())\n",
        "\n",
        "optimal_k = k_values[np.argmax(cv_scores)]\n",
        "print(f\"Optimal k determined: {optimal_k}\")\n",
        "\n",
        "# Plot k-optimization curve\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(k_values, cv_scores, 'rs-', markersize=4)\n",
        "plt.axvline(x=optimal_k, color='k', linestyle='--', label=f'Best k={optimal_k}')\n",
        "plt.title('Model Performance ($R^2$) vs. Number of Features (k)')\n",
        "plt.xlabel('k (Number of selected features)')\n",
        "plt.ylabel('CV $R^2$ Score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SCnt1L7xNGD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# k=22 yields the best R² performance.\n",
        "optimal_k = 22\n",
        "# Ensure k does not exceed the total number of features.\n",
        "k_best = min(optimal_k, X_reduced.shape[1])\n",
        "\n",
        "# Initialize SelectKBest using f_regression as the scoring function.\n",
        "selector = SelectKBest(score_func=f_regression, k=k_best)\n",
        "\n",
        "# Fit the selector to X_reduced and transform. All 2400 samples are kept.\n",
        "X_selected = selector.fit_transform(X_reduced, y)\n",
        "\n",
        "print(f\"Original PCA features: {X_reduced.shape[1]}\")\n",
        "print(f\"Selected features: {X_selected.shape[1]}\")\n",
        "\n",
        "\n",
        "# Retrieve raw F-scores for all PCA components.\n",
        "feature_scores = selector.scores_\n",
        "\n",
        "# Get a boolean mask for the selected features.\n",
        "selected_features = selector.get_support()\n",
        "\n",
        "print(f\"Feature scores for PCA components (top {k_best}):\")\n",
        "\n",
        "# Get the actual indices of the selected features.\n",
        "selected_indices = np.where(selected_features)[0]\n",
        "\n",
        "\n",
        "# Loop through and print selected PC indices and their scores.\n",
        "for i, (idx, score) in enumerate(zip(selected_indices, feature_scores[selected_features])):\n",
        "\n",
        "    # Use idx+1 to make PC numbering more intuitive.\n",
        "    print(f\"PC{idx+1}: {score:.2f}\")\n",
        "\n",
        "# Visualize Feature Importance\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Comparing scores of all PCA components\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(range(len(feature_scores)), feature_scores)\n",
        "plt.title('Feature Importance Scores (All PCA Components)')\n",
        "plt.xlabel('PCA Component Index')\n",
        "plt.ylabel('F-score')\n",
        "plt.xticks(range(0, len(feature_scores), 5))\n",
        "\n",
        "\n",
        "# Visualizing the top 22 selected features\n",
        "plt.subplot(1, 2, 2)\n",
        "selected_scores = feature_scores[selected_features]\n",
        "plt.bar(range(len(selected_scores)), selected_scores, color='orange')\n",
        "plt.title(f'Selected Top {k_best} Features')\n",
        "plt.xlabel('Selected Feature Rank')\n",
        "plt.ylabel('F-score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nFinal feature matrix shape: {X_selected.shape}\")"
      ],
      "metadata": {
        "id": "ozlnzVQaXihC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I utilized the SelectKBest algorithm from Scikit-Learn, which ranks features based on their statistical significance. The f_regression function was chosen as the scoring metric. It computes the F-statistic to evaluate the linear correlation between each chemical descriptor and the Bandgap.By identifying the top 22 features, I effectively reduced the dimensionality of the input space. This balance ensures high predictive accuracy while preventing the model from over-fitting to irrelevant features."
      ],
      "metadata": {
        "id": "5QQV3I0F2xe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.6 Cross-Validation Strategy and Model Training**"
      ],
      "metadata": {
        "id": "J64V1mWKX4WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_selected, y, test_size=0.2, random_state=1003\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Testing set size: {X_val.shape}\")\n",
        "\n",
        "# Define Random Forest Regressor with hyperparameter tuning\n",
        "rf_regressor = RandomForestRegressor(random_state=1003)\n",
        "\n",
        "# Hyperparameter grid for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Use GridSearchCV for hyperparameter optimization\n",
        "cv_folds = min(5, len(X_train) // 3)\n",
        "print(f\"Using {cv_folds}-fold cross-validation\")\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_regressor,\n",
        "    param_grid=param_grid,\n",
        "    cv=cv_folds,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "print(\"Training Random Forest Regressor with Grid Search...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_rf = grid_search.best_estimator_\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best CV score: {-grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = best_rf.predict(X_train)\n",
        "y_val_pred = best_rf.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "val_mse = mean_squared_error(y_val, y_val_pred)\n",
        "\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "val_r2 = r2_score(y_val, y_val_pred)\n",
        "\n",
        "print(\"\\nModel Performance:\")\n",
        "print(f\"Training MSE: {train_mse:.4f}\")\n",
        "print(f\"Validation MSE: {val_mse:.4f}\")\n",
        "print(f\"Training MAE: {train_mae:.4f}\")\n",
        "print(f\"Validation MAE: {val_mae:.4f}\")\n",
        "print(f\"Training R²: {train_r2:.4f}\")\n",
        "print(f\"Validation R²: {val_r2:.4f}\")\n",
        "\n",
        "# Feature importance from the best model\n",
        "feature_importance = best_rf.feature_importances_\n",
        "print(\"\\nFeature Importance (Selected PCA Components):\")\n",
        "for i, importance in enumerate(feature_importance):\n",
        "    print(f\"Feature {i+1}: {importance:.4f}\")"
      ],
      "metadata": {
        "id": "SoAVxpzdX40e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Visualizing 5-Fold Cross-Validation Parity Plots\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1003)\n",
        "fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n",
        "\n",
        "y_np = y.values if hasattr(y, 'values') else y\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(kf.split(X_selected)):\n",
        "    X_train_fold, X_val_fold = X_selected[train_index], X_selected[val_index]\n",
        "    y_train_fold, y_val_fold = y_np[train_index], y_np[val_index]\n",
        "\n",
        "    # Train model\n",
        "    best_rf.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict\n",
        "    y_pred_fold = best_rf.predict(X_val_fold)\n",
        "    fold_r2 = r2_score(y_val_fold, y_pred_fold)\n",
        "\n",
        "    # Plotting\n",
        "    ax = axes[i]\n",
        "    ax.scatter(y_val_fold, y_pred_fold, color='blue', alpha=0.5, s=20)\n",
        "\n",
        "    # Diagonal line\n",
        "    all_vals = np.concatenate([y_val_fold, y_pred_fold])\n",
        "    min_v, max_v = all_vals.min(), all_vals.max()\n",
        "    ax.plot([min_v, max_v], [min_v, max_v], 'r-', lw=2, label=f'$R^2$ = {fold_r2:.2f}')\n",
        "\n",
        "    ax.set_title(f'Fold {i+1}')\n",
        "    ax.set_xlabel('Actual')\n",
        "    ax.set_ylabel('Predicted')\n",
        "    ax.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QBtu0VRVN2b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 5-fold cross-validation results indicate that the model possesses robust predictive power across different data subsets, with R2 scores ranging from 0.60 to 0.67. In the scatter plots, the predicted values are closely distributed around the y=x reference line, demonstrating that the model has successfully captured the underlying physical relationship between descriptors and the bandgap. It validates the model's generalization capability."
      ],
      "metadata": {
        "id": "naoGl3uFvjtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.7 Results Visualization and Analysis**"
      ],
      "metadata": {
        "id": "Z3c9h6mqgu2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Predicted vs Actual & Residuals ---\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "#  Training Predicted vs Actual\n",
        "axes[0, 0].scatter(y_train, y_train_pred, alpha=0.7, color='blue', label=f'Training ($R^2$={train_r2:.3f})')\n",
        "axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
        "axes[0, 0].set_title(f'Training Set: Predicted vs Actual\\n$R^2$ = {train_r2:.4f}, MAE = {train_mae:.4f}')\n",
        "axes[0, 0].set_xlabel('Actual Bandgap (eV)')\n",
        "axes[0, 0].set_ylabel('Predicted Bandgap (eV)')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Validation Predicted vs Actual\n",
        "axes[0, 1].scatter(y_val, y_val_pred, alpha=0.7, color='red', label=f'Validation ($R^2$={val_r2:.3f})')\n",
        "axes[0, 1].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
        "axes[0, 1].set_title(f'Validation Set: Predicted vs Actual\\n$R^2$ = {val_r2:.4f}, MAE = {val_mae:.4f}')\n",
        "axes[0, 1].set_xlabel('Actual Bandgap (eV)')\n",
        "axes[0, 1].set_ylabel('Predicted Bandgap (eV)')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3 (Left): Training Residuals\n",
        "# Residuals = Actual - Predicted\n",
        "axes[1, 0].scatter(y_train_pred, y_train - y_train_pred, alpha=0.7, color='blue')\n",
        "axes[1, 0].axhline(y=0, color='r', linestyle='--')\n",
        "axes[1, 0].set_title('Training Set: Residuals')\n",
        "axes[1, 0].set_xlabel('Predicted Bandgap (eV)')\n",
        "axes[1, 0].set_ylabel('Residuals')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Validation Residuals\n",
        "axes[1, 1].scatter(y_val_pred, y_val - y_val_pred, alpha=0.7, color='red')\n",
        "axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
        "axes[1, 1].set_title('Validation Set: Residuals')\n",
        "axes[1, 1].set_xlabel('Predicted Bandgap (eV)')\n",
        "axes[1, 1].set_ylabel('Residuals')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3xYu3jsUgvIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final model assessment reveals exceptional accuracy on the training set (R2 = 0.947, MAE = 0.2805 eV), while the validation set maintains a solid R2 of 0.6698 (MAE = 0.6631 eV), confirming the model’s ability to generalize effectively without significant overfitting. Residual plots indicate that while most errors are centered around the zero-line, there is increased variance in the low-bandgap region (< 2 eV) and a few notable outliers in the 3-5 eV range of the validation set."
      ],
      "metadata": {
        "id": "6Pk35wzJwxvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the actual indices of the selected features from the original 60 PCs\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Create specific PC label names (e.g., PC1, PC2, PC5...)\n",
        "pc_names = [f\"PC{i+1}\" for i in selected_indices]\n",
        "\n",
        "# Get and Sort Importance Scores\n",
        "importances = best_rf.feature_importances_\n",
        "\n",
        "# Sort for better visualization\n",
        "sorted_idx = np.argsort(importances)[::-1]\n",
        "sorted_importances = importances[sorted_idx]\n",
        "sorted_pc_names = [pc_names[i] for i in sorted_idx]\n",
        "\n",
        "# Plot Updated Feature Importance\n",
        "plt.figure(figsize=(14, 7))\n",
        "bars = plt.bar(range(len(sorted_importances)), sorted_importances, color='skyblue', edgecolor='black')\n",
        "\n",
        "# Replace x-axis with actual Principal Component names\n",
        "plt.xticks(range(len(sorted_importances)), sorted_pc_names, rotation=45)\n",
        "\n",
        "plt.title(f'Random Forest Feature Importance\\n(Mapped to Original Principal Components)')\n",
        "plt.xlabel('Principal Component (Ranked by Importance)')\n",
        "plt.ylabel('Importance Score')\n",
        "\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f'{yval:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Top 5 Contributing Principal Components:\")\n",
        "for i in range(5):\n",
        "    print(f\"{sorted_pc_names[i]}: {sorted_importances[i]:.4f}\")"
      ],
      "metadata": {
        "id": "TPbGr7UbvKsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The feature importance chart reveals that the Random Forest model primarily relies on the core components derived from PCA, with PC1 (0.1960) and PC2 (0.1656) standing out as the most influential descriptors. Although the importance scores decrease rapidly, PC5, PC3, and others indicate that bandgap prediction is driven by a complex interplay of multiple physical factors."
      ],
      "metadata": {
        "id": "ToNUNKcuyaxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.8 Final Hold-out Test Evaluation**"
      ],
      "metadata": {
        "id": "PFqB3vPFwRhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Use objects fitted on training data to transform test data\n",
        "X_test_scaled = scaler.transform(X_test_raw)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "X_test_selected = selector.transform(X_test_pca)\n",
        "\n",
        "# Final Prediction\n",
        "y_test_pred = best_rf.predict(X_test_selected)\n",
        "\n",
        "# Calculate Final Metrics\n",
        "test_r2 = r2_score(y_test_true, y_test_pred)\n",
        "test_mae = mean_absolute_error(y_test_true, y_test_pred)\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test_true, y_test_pred))\n",
        "\n",
        "print(f\"--- Final Hold-out Test Performance (600 samples) ---\")\n",
        "print(f\"Final R² Score: {test_r2:.4f}\")\n",
        "print(f\"Final MAE: {test_mae:.4f} eV\")\n",
        "print(f\"Final RMSE: {test_rmse:.4f} eV\")\n",
        "\n",
        "# Visualization: Predicted vs Actual\n",
        "plt.figure(figsize=(8, 7))\n",
        "plt.scatter(y_test_true, y_test_pred, alpha=0.6, color='forestgreen', edgecolors='w', label=f'Hold-out Test ($R^2$={test_r2:.3f})')\n",
        "\n",
        "# Plot 45-degree reference line\n",
        "min_val = min(y_test_true.min(), y_test_pred.min())\n",
        "max_val = max(y_test_true.max(), y_test_pred.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "\n",
        "plt.title(f'Final Evaluation: Predicted vs Actual', fontsize=14)\n",
        "plt.xlabel('Actual Bandgap (eV)', fontsize=12)\n",
        "plt.ylabel('Predicted Bandgap (eV)', fontsize=12)\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualization: Final Residuals\n",
        "plt.figure(figsize=(8, 5))\n",
        "residuals = y_test_true - y_test_pred\n",
        "plt.scatter(y_test_pred, residuals, alpha=0.6, color='forestgreen', edgecolors='w')\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title('Final Evaluation: Residual Distribution', fontsize=14)\n",
        "plt.xlabel('Predicted Bandgap (eV)', fontsize=12)\n",
        "plt.ylabel('Residuals (eV)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6jLhZZauwR57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two plots present the final evaluation of the model on 600 completely independent external samples. The results highlight the model's good generalization capability, with a test R2 of 0.690, which is highly consistent with the earlier validation performance, proving the model's stability on unseen data. In the scatter plot, the predicted values closely track the actual values with a MAE of 0.6698 eV. The residual distribution shows that errors are symmetrically centered around the zero-line without significant systematic bias."
      ],
      "metadata": {
        "id": "AtPHupeuy3iB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.9 Analysis of Minimum Training Samples**"
      ],
      "metadata": {
        "id": "y50TzztKHZdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "# Learning Curve Analysis\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    best_rf, X_selected, y, cv=5,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
        "    scoring='r2', n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate mean and standard deviation for the scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# Plotting the learning curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"blue\", label=\"Training Score\")\n",
        "plt.plot(train_sizes, val_mean, 's-', color=\"green\", label=\"Cross-validation Score\")\n",
        "\n",
        "# Fill the area between the standard deviations to show variance\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"blue\")\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color=\"green\")\n",
        "\n",
        "plt.title('Model Performance vs. Number of Training Samples', fontsize=14)\n",
        "plt.xlabel('Number of Training Samples', fontsize=12)\n",
        "plt.ylabel('$R^2$ Score', fontsize=12)\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q9luFDefHZxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced Method: Marginal Gain Analysis\n",
        "# Calculate the derivative of the Cross-validation score to find the plateau\n",
        "\n",
        "# Calculate the improvement (delta) between each step\n",
        "cv_mean = np.mean(val_scores, axis=1)\n",
        "marginal_gains = np.diff(cv_mean) / np.diff(train_sizes)\n",
        "\n",
        "# Define a threshold for saturation\n",
        "threshold = 0.00005\n",
        "plateau_index = np.where(marginal_gains < threshold)[0]\n",
        "\n",
        "if len(plateau_index) > 0:\n",
        "    min_samples = train_sizes[plateau_index[0]]\n",
        "    print(f\"Mathematical Plateau reached at: {int(min_samples)} samples\")\n",
        "else:\n",
        "    min_samples = train_sizes[-1]\n",
        "    print(\"Model has not fully plateaued yet.\")\n",
        "\n",
        "# Visualization of Marginal Gains\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_sizes[1:], marginal_gains, 'o-', color='purple', label='Marginal $R^2$ Gain')\n",
        "plt.axhline(y=threshold, color='r', linestyle='--', label='Saturation Threshold')\n",
        "plt.title('Marginal Utility of Additional Samples')\n",
        "plt.xlabel('Number of Training Samples')\n",
        "plt.ylabel('Improvement in $R^2$ per Sample')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kHjbi6s7MABs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The learning curve illustrates that as the number of training samples grows, the cross-validation R^2 score rises steadily, while the training score remains consistently high at approximately 0.95, suggesting that additional data helps improve generalization despite persistent overfitting. To identify the minimum required dataset size, a marginal utility analysis was performed. A transient dip in marginal gain occurs around 800 samples, causing the mathematical plateau to be triggered prematurely at 576 samples."
      ],
      "metadata": {
        "id": "Q9noA0U4M61A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.10 Interpreting PC Physical Meanings**"
      ],
      "metadata": {
        "id": "ladkPygQ4uDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Loading Data\n",
        "loadings = pd.DataFrame(\n",
        "    pca.components_.T,\n",
        "    columns=[f'PC{i+1}' for i in range(pca.n_components_)],\n",
        "    index=X_test_raw.columns  # Use original feature names\n",
        ")\n",
        "\n",
        "# Define Analysis Function\n",
        "def plot_pc_composition(pc_name, top_n=10):\n",
        "\n",
        "    pc_loadings = loadings[pc_name].sort_values(key=abs, ascending=False).head(top_n)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    colors = ['firebrick' if x > 0 else 'steelblue' for x in pc_loadings]\n",
        "    pc_loadings.plot(kind='barh', color=colors)\n",
        "\n",
        "    plt.title(f'Physical Composition of {pc_name}\\n(Top {top_n} Contributing Descriptors)')\n",
        "    plt.xlabel('Weight (Loading Value)')\n",
        "    plt.ylabel('Original Physical Descriptors')\n",
        "    plt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
        "    plt.grid(axis='x', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"--- Top 5 Features for {pc_name} ---\")\n",
        "    print(pc_loadings.head(5))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Based on Random Forest, PC1 and PC2 are the most critical\n",
        "top_important_pcs = ['PC1', 'PC2']\n",
        "\n",
        "for pc in top_important_pcs:\n",
        "    plot_pc_composition(pc)"
      ],
      "metadata": {
        "id": "Fq5S6Z7O4u10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The feature importance results show that PC1 and PC2 are the most critical factors for predicting the bandgap. PC1 is primarily defined by atomic size and periodic position, specifically descriptors like MagpieData maximum Row and MagpieData maximum CovalentRadius. PC2 focuses on electronic characteristics, with MagpieData mean NdValence being the top contributor. Overall, atomic radius and d-orbital valence electrons emerge as the most important features. This is because these properties directly dictate the energy required for electron excitation, which defines the material's bandgap value."
      ],
      "metadata": {
        "id": "n9iNt9CF6oRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3 Summary**"
      ],
      "metadata": {
        "id": "94GcoGHu9Gop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis concludes that the machine learning model successfully captures the relationship between atomic descriptors and electronic properties, achieving a consistent test R2 of 0.69. Key insights reveal that atomic size (CovalentRadius) and electronic configuration (valence electrons) are the important factors governing the bandgap. While PCA effectively compressed the high-dimensional feature space, the learning curve analysis suggests that performance gains from simply increasing the dataset size plateaued at approximately 960 samples. Future work should focus on hyperparameter optimization or incorporating more complex structural descriptors to further reduce the residual errors."
      ],
      "metadata": {
        "id": "GNteHznl9hnw"
      }
    }
  ]
}